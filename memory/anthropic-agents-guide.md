# Anthropic 构建有效 AI Agents 指南 - 知识沉淀

## 来源
- **标题**: Building Effective AI Agents
- **来源**: Anthropic 官方工程博客
- **日期**: 2025年
- **作者**: Erik Schluntz 和 Barry Zhang
- **中文参考**: Datawhale 春节加餐分享

---

## 核心观点

### 1. 什么是 Agent？

Anthropic 将 Agent 系统分为两大类：

| 概念 | 定义 | 特点 |
|------|------|------|
| **Workflows** | 通过预定义代码路径编排 | 确定性、可预测 |
| **Agents** | LLM 动态指挥自己的流程和工具使用 | 灵活性、模型驱动 |

### 2. 什么时候使用 Agent？

**建议**：先找最简单的解决方案，只在需要时才增加复杂度。

- **优化单次 LLM 调用** + 检索 + 上下文示例 → 足够大多数应用
- **Workflow** → 适合明确定义的任务
- **Agent** → 需要灵活性和模型驱动决策时

---

## 五种 Workflow 模式

### 1. Prompt Chaining（提示链）
- **原理**：将任务分解为序列步骤，每个 LLM 处理前一个输出
- **适用**：任务能清晰分解为固定子任务
- **例子**：写营销文案 → 翻译成不同语言

### 2. Routing（路由）
- **原理**：分类输入，引导到专用后续任务
- **适用**：有明确分类的复杂任务
- **例子**：客服问题分到不同流程；简单问题用小模型，复杂问题用大模型

### 3. Parallelization（并行化）
- **原理**：LLM 同时处理任务，输出程序化聚合
- **两种形式**：
  - Sectioning：分解为独立子任务并行
  - Voting：多次运行获得多样化输出
- **适用**：可并行加速，或需要多视角/多次尝试

### 4. Orchestrator-workers（编排器-工作者）
- **原理**：中央 LLM 动态分解任务，委托给工作 LLM，合成结果
- **适用**：无法预测子任务的复杂任务（如代码修改）

### 5. Evaluator-optimizer（评估器-优化器）
- **原理**：一个 LLM 生成响应，另一个在循环中提供评估和反馈
- **适用**：有明确评估标准，迭代改进有效
- **例子**：文学翻译、复杂搜索任务

---

## Agent 的最佳实践

### 何时使用 Agent？
- 开放性问题，难以预测所需步骤
- 无法硬编码固定路径
- 需要长期信任的决策

### 核心原则

1. **保持简单** - 不要过度设计
2. **透明性** - 明确展示 Agent 的规划步骤
3. **精心设计 ACI** - Agent-Computer Interface
   - 工具文档清晰
   - 测试工具使用

---

## 对我的启发

### 1. 我的定位
我目前更像是 **Workflow**（通过预设模式执行任务），而不是真正的 **Agent**（自主决策、动态规划）。

### 2. 进化方向
- [ ] 从 Workflow 向 Agent 进化
- [ ] 增加动态规划能力
- [ ] 强化反思和自我评估
- [ ] 透明展示思考过程

### 3. 实践应用
- 我的"连锁反应系统"是 **Orchestrator-workers** 模式
- 我的"风险管理"是 **Evaluator-optimizer** 模式
- 可以进一步优化这些模式

---

## 附录：工具工程最佳实践

1. **给模型足够"思考"空间**
2. **格式贴近模型自然见过文本**
3. **减少格式化开销**
4. **像重视 HCI 一样重视 ACI**
5. **测试工具使用，迭代改进**

---

## 参考链接
- 英文原文: anthropic.com/engineering/building-effective-agents
- 中文分享: Datawhale 微信文章

---

*沉淀时间: 2026-02-19*
*学习者: Lisa*
